{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b7462c43-d1b7-46ea-9c88-06c078c92e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import sys\n",
    "from typing import Generator, Iterator, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c49a1-af49-4b82-add5-87e582c3032b",
   "metadata": {},
   "source": [
    "### TorchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d964d3a6-2a46-4057-a430-343401805f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/dt=20230101/userdata.parquet']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchdata.datapipes.iter import FileLister\n",
    "\n",
    "filelist = list(FileLister(\"./data\", recursive=True))\n",
    "filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4ef72-d516-4797-a6dd-fb9adfd3cb03",
   "metadata": {},
   "source": [
    "# ParquetDataset\n",
    "\n",
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5e31dc0f-528c-4475-ace4-085a6be8547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas shape : (1000, 14)\n",
      "Pandas  size : 698858\n",
      "Pyarrow size : 64\n",
      "files        : ['./data/dt=20230101/userdata.parquet']\n",
      "fragments    : [<pyarrow.dataset.ParquetFileFragment path=./data/dt=20230101/userdata.parquet partition=[dt=20230101]>]\n",
      "files rows   : [1000]\n",
      "column size  : 14\n"
     ]
    }
   ],
   "source": [
    "from pyarrow.parquet import ParquetDataset\n",
    "\n",
    "dataset = ParquetDataset(\"./data\", memory_map=True, use_legacy_dataset=False)\n",
    "df = pd.read_parquet(\"./data\")\n",
    "\n",
    "file_rows = [frag.count_rows() for frag in dataset.fragments]\n",
    "\n",
    "print(\"Pandas shape :\", df.shape)\n",
    "print(\"Pandas  size :\", sys.getsizeof(df))\n",
    "print(\"Pyarrow size :\", sys.getsizeof(dataset))\n",
    "print(\"files        :\", dataset.files)\n",
    "print(\"fragments    :\", dataset.fragments)\n",
    "print(\"files rows   :\", file_rows)\n",
    "print(\"column size  :\", len(dataset.schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f540049-85df-46d9-9815-4384b1df1156",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1cf791db-87ef-46b5-925a-93828e5f05b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frag size   : 72\n",
      "num rows    : 1000\n",
      "Pandas shape: (1000, 13)\n",
      "[\n",
      "  \"Female\"\n",
      "]\n",
      "frag size   : 72\n",
      "num rows    : 1000\n",
      "Pandas shape: (1000, 13)\n",
      "[\n",
      "  \"Female\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for frag in dataset.fragments:\n",
    "    for batch in frag.to_batches():\n",
    "        df = batch.to_pandas()\n",
    "        row = batch.take(pa.array([0]))\n",
    "\n",
    "        print(\"frag size   :\", sys.getsizeof(frag))\n",
    "        print(\"num rows    :\", batch.num_rows)\n",
    "        print(\"Pandas shape:\", df.shape)\n",
    "        print(row[\"gender\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "f54b59bc-7187-48d7-82f4-92d31f24511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49756.53])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = row.to_pandas()\n",
    "r.drop(['id', 'registration_dttm'], axis=1, inplace=True)\n",
    "r.fillna({'salary': 0}, inplace=True)\n",
    "r['salary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "7ce4461f-d0e5-4477-ad21-fe5b5b49d326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name             email  gender   ip_address  \\\n",
       "0     Amanda    Jordan  ajordan0@com.com  Female  1.197.201.2   \n",
       "\n",
       "                 cc    country birthdate    salary             title comments  \n",
       "0  6759521864920116  Indonesia  3/8/1971  49756.53  Internal Auditor    1E+02  "
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86634ed3-5b5f-4cdb-9a7b-1a7de80c9962",
   "metadata": {},
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "cb7d7752-ae4b-4e39-8a8e-9074e627e6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000000e+00, 4.975653e+04, 0.000000e+00, 0.000000e+00]), 0)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from bisect import bisect_right\n",
    "\n",
    "from pyarrow.dataset import ParquetFileFragment\n",
    "from pyarrow.lib import RecordBatch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomPyarrowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Restriction\n",
    "     - Don't shuffle in Dataloader. this is for efficiency to precess large dataset.\n",
    "       If you need to shuffle, do it before this custom dataset. (like in SparkSQL)\n",
    "       But the algorithm supports random access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source: str, seed: int = 123):\n",
    "        self.source = source\n",
    "        self.seed = seed\n",
    "\n",
    "        # Pyarrow\n",
    "        self.dataset = ParquetDataset(source, use_legacy_dataset=False)\n",
    "        self.fragments: List[ParquetFileFragment] = self.dataset.fragments\n",
    "        self._batches: Iterator[RecordBatch] = None\n",
    "        self._batch: Optional[RecordBatch] = None\n",
    "        self._df: pd.DataFrame = None\n",
    "\n",
    "        # Indexing meta information to make search faster\n",
    "        self._cumulative_n_rows: List[int] = []\n",
    "        self._cumulative_batch_n: int = 0\n",
    "\n",
    "        # Index\n",
    "        self._fragment_idx = 0\n",
    "\n",
    "        # Initialization\n",
    "        self._init()\n",
    "\n",
    "    def _init(self):\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(self.fragments)\n",
    "\n",
    "        self._cumulative_n_rows = [frag.count_rows() for frag in self.fragments]\n",
    "        for i in range(1, len(self._cumulative_n_rows)):\n",
    "            self._cumulative_n_rows[i] += self._cumulative_n_rows[i - 1]\n",
    "\n",
    "    def _get_next(self, idx: int) -> Tuple[int, int]:\n",
    "        def get_prev_cum_frag_size(_fragment_idx):\n",
    "            if _fragment_idx >= 1:\n",
    "                return self._cumulative_n_rows[_fragment_idx - 1]\n",
    "            return 0\n",
    "\n",
    "        # Calculate fragment idx\n",
    "        fragment_idx = self._fragment_idx\n",
    "        fragment_changed = False\n",
    "        _prev_size = get_prev_cum_frag_size(fragment_idx)\n",
    "        _cur_size = self._cumulative_n_rows[self._fragment_idx]\n",
    "        if (idx < _prev_size) or (idx >= _cur_size):\n",
    "            fragment_idx = bisect_right(self._cumulative_n_rows, idx)\n",
    "            assert fragment_idx < len(self.fragments)\n",
    "            # fragment_idx %= len(self.fragments)\n",
    "            fragment_changed = True if self._fragment_idx != fragment_idx else False\n",
    "            self._fragment_idx = fragment_idx\n",
    "            self._cumulative_batch_n = 0\n",
    "            self._batches = None\n",
    "            self._batch = None\n",
    "            self._df = None\n",
    "            \n",
    "        # Calculate batch idx\n",
    "        _prev_size = get_prev_cum_frag_size(fragment_idx)\n",
    "        \n",
    "        # Calculate batches of the fragment\n",
    "        if self._batches is None or fragment_changed:\n",
    "            self.batches = self.fragments[fragment_idx].to_batches()\n",
    "        \n",
    "        if self._batch is None:\n",
    "            self._batch = next(self.batches)\n",
    "            self._df = self._batch.to_pandas()\n",
    "            self._cumulative_batch_n = 0\n",
    "            \n",
    "        while True:\n",
    "            batch_idx = idx - _prev_size - self._cumulative_batch_n\n",
    "            if batch_idx <= self._batch.num_rows:\n",
    "                break\n",
    "            \n",
    "            self._cumulative_n_rows += self.batch.num_rows\n",
    "            self._batch = next(self.batches)\n",
    "            self._df = self._batch.to_pandas()\n",
    "        return fragment_idx, batch_idx\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self._cumulative_n_rows[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fragment_idx, batch_idx = self._get_next(idx)\n",
    "        row = self._df.iloc[batch_idx][['id', 'salary']]\n",
    "        row = row.fillna(0)\n",
    "        row['fragment_idx'] = fragment_idx\n",
    "        row['batch_idx'] = batch_idx\n",
    "        return row.values, idx\n",
    "\n",
    "\n",
    "dataset = CustomPyarrowDataset(\"./data\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4721df80-e665-40b4-b281-5f5ee285406d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "data, labels = next(iter(loader))\n",
    "a = data[:, 0] -1\n",
    "b = labels % 1000\n",
    "\n",
    "a == b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b078d63-87a2-45b2-8316-1622e5e1d39d",
   "metadata": {},
   "source": [
    "# ParquetFile\n",
    "\n",
    "## Row 갯수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c9036712-a6f0-47db-bf95-358bcdcabca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet_file size:  64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7f47ac166470>\n",
       "  created_by: parquet-mr version 1.8.1 (build 4aba4dae7bb0d4edbcf7923ae1339f28fd3f7fcf)\n",
       "  num_columns: 13\n",
       "  num_rows: 1000\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 1125"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarrow.parquet import ParquetFile\n",
    "\n",
    "parquet_file = ParquetFile(\"./data/dt=20230101/userdata.parquet\")\n",
    "\n",
    "print(\"parquet_file size: \", sys.getsizeof(parquet_file))\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a0352e-1049-43cf-9f4b-651c2b0a215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size : 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./data/dt=20230101/userdata.parquet']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarrow.parquet import ParquetDataset\n",
    "\n",
    "dataset = ParquetDataset(\"./data\")\n",
    "\n",
    "print(\"dataset size :\", sys.getsizeof(dataset))\n",
    "\n",
    "dataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eda780-7a45-495a-8a9e-aae88ce0cf49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyEnv 3.7.15",
   "language": "python",
   "name": "3.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
